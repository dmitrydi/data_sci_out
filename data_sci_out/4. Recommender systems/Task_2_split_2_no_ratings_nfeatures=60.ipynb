{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games RSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# импорты, которые точно понадобятся\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "from scipy.sparse import save_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Данные взяты отсюда - http://jmcauley.ucsd.edu/data/amazon/\n",
    "# http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz\n",
    "JSON_DATA_PATH = \"lab_data/Video_Games_5.json\"\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def iter_json_data(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "            \n",
    "def get_data_frame():\n",
    "    uid_to_id = {}\n",
    "    iid_to_id = {}\n",
    "    \n",
    "    cols = [\"uid\", \"iid\", \"review\", \"rating\", \"dt\"]\n",
    "    rows = []\n",
    "    for d in iter_json_data(JSON_DATA_PATH):\n",
    "        uid = uid_to_id.setdefault(d[\"reviewerID\"], len(uid_to_id))\n",
    "        iid = iid_to_id.setdefault(d[\"asin\"], len(iid_to_id))\n",
    "        review = d[\"reviewText\"]\n",
    "        rating = float(d[\"overall\"])\n",
    "        dt = int(d[\"unixReviewTime\"])\n",
    "        rows.append((uid, iid, review, rating, dt))\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1403913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1315958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid                                             review  rating  \\\n",
       "0    0    0  Installing the game was a struggle (because of...     1.0   \n",
       "1    1    0  If you like rally cars get this game you will ...     4.0   \n",
       "2    2    0  1st shipment received a book instead of the ga...     1.0   \n",
       "3    3    0  I got this version instead of the PS3 version,...     3.0   \n",
       "4    4    0  I had Dirt 2 on Xbox 360 and it was an okay ga...     4.0   \n",
       "\n",
       "           dt  \n",
       "0  1341792000  \n",
       "1  1372550400  \n",
       "2  1403913600  \n",
       "3  1315958400  \n",
       "4  1308009600  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min-max количество объектов на пользователя: 5 773\n",
      "min-max количество пользователей на объект: 5 802\n"
     ]
    }
   ],
   "source": [
    "print(\"min-max количество объектов на пользователя:\", \n",
    "      df.groupby(\"uid\").iid.nunique().min(), df.groupby(\"uid\").iid.nunique().max())\n",
    "print(\"min-max количество пользователей на объект:\", \n",
    "      df.groupby(\"iid\").uid.nunique().min(), df.groupby(\"iid\").uid.nunique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем, есть ли случаи, когда один и тот же пользователь оставляет отзывы на один и тот же объект\n",
    "df.groupby([\"uid\", \"iid\"]).review.count().unique()  # ура, таких случаев нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов: 10672\n",
      "Количество пользователей: 24303\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество объектов:\", df.iid.unique().size)\n",
    "print(\"Количество пользователей:\", df.uid.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df_by_dt(df, p=0.8):\n",
    "    \"\"\"Функция разбивает df на тестовую и тренировочную выборки по времени \n",
    "    публикации отзывов (значение времени в поле dt)\n",
    "    \n",
    "    :param p: персентиль значений dt, которые образуют тренировочную выборку. Например p=0.8 означает, что в \n",
    "    тренировочной части будут отзывы, соответствующие первым 80% временного интервала \n",
    "    :return: два pd.DataFrame объекта\n",
    "    \"\"\"\n",
    "    border_dt = df.dt.quantile(p)\n",
    "    print(\"Min=%s, border=%s, max=%s\" % (df.dt.min(), border_dt, df.dt.max()))\n",
    "    training_df, test_df  = df[df.dt <= border_dt], df[df.dt > border_dt]\n",
    "    print(\"Размер до очистки:\", training_df.shape, test_df.shape)\n",
    "    # удаляем из тестовых данных строки, соответствующие пользователям или объектам, \n",
    "    # которых нет в тренировочных данных \n",
    "    # (пользователи - избегаем проблем для персональных систем, объекты - для всех)\n",
    "    test_df = test_df[test_df.uid.isin(training_df.uid) & test_df.iid.isin(training_df.iid)]\n",
    "    print(\"Размер после очистки:\", training_df.shape, test_df.shape)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min=939859200, border=1377129600.0, max=1405987200\n",
      "Размер до очистки: (185427, 5) (46353, 5)\n",
      "Размер после очистки: (185427, 5) (19174, 5)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = split_df_by_dt(df, p=0.8)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df(df, min_review_per_uid, min_review_per_iid):\n",
    "    \"\"\"Функция удаляет из df строки, соответствующие пользователям и объектам, \n",
    "    у которых меньше min_review_per_uid и min_review_per_iid отзывов соответственно\n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "    while True:\n",
    "        review_per_uid = _df.groupby(\"uid\").review.count()\n",
    "        bad_uids = review_per_uid[review_per_uid < min_review_per_uid].index\n",
    "    \n",
    "        review_per_iid = _df.groupby(\"iid\").review.count()\n",
    "        bad_iids = review_per_iid[review_per_iid < min_review_per_iid].index\n",
    "        \n",
    "        if bad_uids.shape[0] > 0 or bad_iids.shape[0] > 0:\n",
    "            _df = _df[(~_df.uid.isin(bad_uids)) & (~_df.iid.isin(bad_iids))]\n",
    "        else:\n",
    "            break\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_ratio(recs_dict, test_dict):\n",
    "    \"\"\"Функция считает метрику hit-ration для двух словарей\n",
    "    :recs_dict: словарь рекомендаций типа {uid: {iid: score, ...}, ...}\n",
    "    :test_dict: тестовый словарь типа {uid: {iid: score, ...}, ...}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for uid in test_dict:\n",
    "        if set(test_dict[uid].keys()).intersection(recs_dict.get(uid, {})):\n",
    "            hits += 1\n",
    "    return hits / len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_dict(test_df):\n",
    "    \"\"\"Функция, конвертирующая тестовый df в словарь\n",
    "    \"\"\"\n",
    "    test_dict = {}\n",
    "    for t in test_df.itertuples():\n",
    "        test_dict.setdefault(t.uid, {})\n",
    "        test_dict[t.uid][t.iid] = t.rating\n",
    "    return test_dict\n",
    "\n",
    "test_dict = get_test_dict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение задачи на блоки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nsplit = 25\n",
    "uid_to_ind_train = {}\n",
    "uid_to_ind_test = {}\n",
    "\n",
    "unique_users_train = training_df.uid.unique()\n",
    "n_unique_train = len(unique_users_train)\n",
    "\n",
    "unique_users_test = test_df.uid.unique()\n",
    "n_unique_test = len(unique_users_test)\n",
    "\n",
    "for uid in unique_users_train:\n",
    "    uid_to_ind_train[uid] = uid_to_ind_train.setdefault(uid, len(uid_to_ind_train))\n",
    "    \n",
    "for uid in unique_users_test:\n",
    "    uid_to_ind_test[uid] = uid_to_ind_test.setdefault(uid, len(uid_to_ind_test))\n",
    "    \n",
    "ind_to_uid_train = { v: k for k, v in uid_to_ind_train.items() }\n",
    "ind_to_uid_test = { v: k for k, v in uid_to_ind_test.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "block_len = ceil(n_unique_train/Nsplit)\n",
    "\n",
    "# создаем список диапазонов индексов\n",
    "block_list = [] # элементы списка - локальные индексы пользователей в блоке [ {id: uid, ...}, ...]\n",
    "for i in range(Nsplit):\n",
    "    start = i*block_len\n",
    "    end = (i+1)*block_len\n",
    "    loc_ind = 0\n",
    "    dummy_dict = {}\n",
    "    for j in range(start, min(end, n_unique_train)):\n",
    "        dummy_dict[loc_ind] = ind_to_uid_train[j]\n",
    "        loc_ind += 1\n",
    "    block_list.append(dummy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # элементы списка - локальные индексы пользователей в блоке [ {uid: id, ...}, ...]\n",
    "uid_block_list = [ { v: k for k, v in block_list[i].items() } for i in range(Nsplit)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_block_number(id_, list_of_blocks):\n",
    "    for i in range(len(list_of_blocks)):\n",
    "        if id_ in list_of_blocks[i].keys():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for uid in unique_users_test:\n",
    "    data.append((uid, get_block_number(uid, uid_block_list)))\n",
    "uids_test_map = pd.DataFrame(data, columns=['uid', 'block'], dtype='int64')\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые классы для рекомендательной системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicRecommender(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        \"\"\"Строит рекомендации для пользователя uid\n",
    "        :return: словарь типа {iid: score, ...}\n",
    "        \"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        \"\"\"Строит рекомендации для нескольких пользователей uids\n",
    "        :return: словарь типа {uid: {iid: score, ...}, ...}\n",
    "        \"\"\"\n",
    "        return {uid: self.get_recs(uid, top) for uid in uids}\n",
    "    \n",
    "class NonPersRecommender(BasicRecommender):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.recs = self._prepare_recs(df)\n",
    "        \n",
    "    def _prepare_recs(self, df):\n",
    "        return pd.Series([])\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        from collections import OrderedDict\n",
    "        return OrderedDict(self.recs[:top])\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        non_pers_recs = self.get_recs(None, top)\n",
    "        return {uid: non_pers_recs for uid in uids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выбирает соответсвие id объекта - rating, уже приобретенные объекты (exclude keys) исключаются\n",
    "def select_item(source_matrix, keys_to_index, key_, exclude_keys):\n",
    "    if key_ in exclude_keys:\n",
    "        return 0\n",
    "    else:\n",
    "        return source_matrix[0, keys_to_index[key_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContentBasedRecommender_dummy(NonPersRecommender):\n",
    "    \n",
    "    def __init__(self, uid_to_ind, iid_to_ind, train_df, sim_matrix):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.uid_to_ind = uid_to_ind\n",
    "        self.iid_to_ind = iid_to_ind\n",
    "        self.train_df = train_df\n",
    "        self.sim_matrix = sim_matrix\n",
    "        #self.recs = self._prepare_recs(uid_to_ind, iid_to_ind, train_df, sim_matrix)\n",
    "        \n",
    "    def get_recs(self, uids_to_recommend, top_k=10):\n",
    "        self.recs = self._prepare_recs(uids_to_recommend, self.uid_to_ind, self.iid_to_ind, self.train_df, self.sim_matrix, top_k)\n",
    "        return self.recs\n",
    "        \n",
    "    def _prepare_recs(self, uids_to_recommend, uid_to_ind, iid_to_ind, train_df, sim_matrix, top_k):\n",
    "        out = {}\n",
    "        for uid in uids_to_recommend:\n",
    "            already_bought_items = train_df[train_df.uid == uid].iid.values\n",
    "            sim_row = sim_matrix.getrow(uid_to_ind[uid]).todense()\n",
    "            item_with_score = { iid: select_item(sim_row, iid_to_ind, iid, already_bought_items) for iid in iid_to_ind.keys() }\n",
    "            dummy = pd.Series(item_with_score).sort_values(ascending=False)[:top_k].to_dict()\n",
    "            out[uid] = dummy\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизуем объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_ids = training_df.iid.unique() # уникальные идентификаторы объектов в тренировочной выборке\n",
    "id_to_ind = {}\n",
    "texts = []\n",
    "\n",
    "# для каждого id из item_ids формируется \"суммарное\" описание из отзывово нескольких пользователей\n",
    "for id in item_ids:\n",
    "    text = training_df[training_df.iid == id].review.str.cat(sep=' ')\n",
    "    texts.append(text)\n",
    "    id_to_ind[id] = id_to_ind.setdefault(id, len(id_to_ind)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tfidf = TfidfVectorizer(stop_words='english', max_features=60000)\n",
    "items_matrix = my_tfidf.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del my_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10098x60000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7188097 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011863895490856275"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix.nnz/(items_matrix .shape[0]*items_matrix .shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DICT_LEN = items_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 block done\n",
      "1 block done\n",
      "2 block done\n",
      "3 block done\n",
      "4 block done\n",
      "5 block done\n",
      "6 block done\n",
      "7 block done\n",
      "8 block done\n",
      "9 block done\n",
      "10 block done\n",
      "11 block done\n",
      "12 block done\n",
      "13 block done\n",
      "14 block done\n",
      "15 block done\n",
      "16 block done\n",
      "17 block done\n",
      "18 block done\n",
      "19 block done\n",
      "20 block done\n",
      "21 block done\n",
      "22 block done\n",
      "23 block done\n",
      "24 block done\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "gl_recs = {} #будущий словарь с рекомендациями\n",
    "\n",
    "for i in range(Nsplit):\n",
    "    block = block_list[i]\n",
    "    uid_to_ind_loc = uid_block_list[i]                # локальное соответсвие uid - номер строки\n",
    "    uids_to_recommend = uids_test_map[uids_test_map.block == i].uid.values\n",
    "    for j in range(len(block)):\n",
    "        uid = block[j]\n",
    "        user_df = training_df[training_df.uid == uid] # выбираем кусок df, соответствующий пользователю\n",
    "        user_items = user_df.iid                      # список объектов, оцененных пользователем\n",
    "        user_time = user_df.dt                        # время отзывов пользователя\n",
    "        user_vect = csr_matrix((1, DICT_LEN))         # инициализируем пустой вектор пользователя\n",
    "        user_time = user_time/max(user_time)\n",
    "\n",
    "        for iid, time in zip(user_items, user_time):\n",
    "            item_vect = items_matrix.getrow(id_to_ind[iid])\n",
    "            user_vect += item_vect.multiply(time)     # идея в том, что чем новее отзыв, тем большую актуальность тема представляет для него сейчас\n",
    "            \n",
    "        try:\n",
    "            users_matrix = vstack([users_matrix, user_vect])\n",
    "        except NameError:\n",
    "            users_matrix = user_vect                 # составили \"локальную\" матрицу пользователей\n",
    "            \n",
    "    sim_matrix = cosine_similarity(users_matrix, items_matrix, dense_output=False) # матрица схожести\n",
    "    recommender = ContentBasedRecommender_dummy(uid_to_ind_loc, id_to_ind, training_df, sim_matrix)\n",
    "    recs = recommender.get_recs(uids_to_recommend)\n",
    "    gl_recs.update(recs)\n",
    "    del users_matrix, sim_matrix\n",
    "    print(\"{} block done\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uids_to_recommend = uids_test_map[uids_test_map.block == i].uid.values\n",
    "# test__ = test_df.loc[test_df.uid.isin(uids_to_recommend)]\n",
    "# dummy_test_dict = get_test_dict(test__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06001467351430668"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_ratio(gl_recs, test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HR@10` для item-based CF модели, созданной автором блокнота: 0.085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подcказки\n",
    "* Определитесь с тем, что вы пытаетесь предсказать (рейтинги, вероятности, ...)\n",
    "* Оптимальный способ вычисления матрицы схожести выглядит так:\n",
    " * Привести строки в матрице `user x item` к единичной длине (выделяет основные предпочтения пользователя)\n",
    " * Построить матрицу схожести `item x item`\n",
    " * Для каждого объекта оставить только $K$ наиболее похожих объектов\n",
    " * Для каждого объекта привести к единичной длине вектор схожести этого объекта (выделяет наиболее схожие объекты)\n",
    "* Удалили ли вы из рекомендаций объекты, которые пользователь уже оценивал?\n",
    "* Статья \"Item-Based Top-N Recommendation Algorithms\", Mukund Deshpande и George Karypis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
