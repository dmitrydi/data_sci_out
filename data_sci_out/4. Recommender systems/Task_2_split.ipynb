{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного задания, студент должен создать и оценить 4 типа рекомендательных систем:\n",
    "* Non-personalized RS\n",
    "* Content-based RS\n",
    "* Item-based collaborative filtering RS\n",
    "* Hybrid RS\n",
    "\n",
    "Каждая рекомендательная система - отдельное подзадание. Подзадание считается выполненным, если студент создал рекомендательную систему, которая **лучше (или хуже, но не более чем на 10%)** системы, созданной автором данного блокнота. Системы оцениваются с использованием метрики ``HR@N``, описанной ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Детальное описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Данные: \n",
    "Датасет представлен множеством отзывов к компьютерным играм (объектам) от пользователей Amazon. Каждый отзыв представлен в виде JSON-структуры со следующими полями:\n",
    "* идентификатор пользователя - reviewerID\n",
    "* идентификатор объекта - asin\n",
    "* текст отзыва - reviewText\n",
    "* рейтинг - overall\n",
    "* время публикации обзора - unixReviewTime\n",
    "* другие поля, не использованные автором этого блокнота (смотри полное описание JSON [тут](http://jmcauley.ucsd.edu/data/amazon/))\n",
    "\n",
    "У каждого объекта есть как минимум 5 отзывов, каждый пользователь написал как минимум 5 отзывов. \n",
    "#### Цель: \n",
    "Построить рекомендательную систему, предсказывающую объекты, которые пользователь приобретет в ближайшем будущем. Для упрощения мы считаем, что пользователь приобрел объект, если он написал про него отзыв.\n",
    "#### Подготовка данных:\n",
    "Данные разделены на тренировочную и тестовую выборки по времени публикации отзывов. Первые 80% данных (более старые) используются как тренировочная выборка, остальные - как тестовая. \n",
    "\n",
    "Построение рекомендательной системы (т.е., выбор и тренировка моделей, оптимизация параметров и т.д.) осуществляется **только** с использованием тренировочной выборки. Все параметры, использованные в моделях, **должны быть** получены или объяснены с помощью тренировочных данных. Студент вправе использовать тренировочную выборку как его душе угодно. \n",
    "\n",
    "Тестирующая выборка используется **только** для оценки рекомендательной системы.\n",
    "\n",
    "Для построения рекомендательных моделей также можно использовать JSON-поля из датасета, неиспользованные автором этого блокнота.\n",
    "#### Оценка качества рекомендательной системы\n",
    "Цель рекомендательной системы - посоветовать пользователю объекты, которые он захочет приобрести. Для оценки качества такой системы мы воспользуемся метрикой `hit-ratio (HR)`. \n",
    "\n",
    "$$\n",
    "HR = \\frac{1}{|U_T|}\\sum_{u \\in U_T} \\mathrm{I}(Rel_u \\cap Rec_u)\n",
    "$$\n",
    "\n",
    "* $U_T$ - множество пользователей из тестовой выборки\n",
    "* $Rec_u$ - множество объектов, рекомендованных пользователю $u$ \n",
    "* $Rel_u$ - множество объектов, оцененных пользователем $u$ в тестовой выборке\n",
    "* $\\mathrm{I}(Rel_u \\cap Rec_u)$ - бинарная функция-индикатор. Функция возвращает 1 если $Rel_u \\cap Rec_u \\ne \\emptyset$, иначе 0\n",
    "\n",
    "$HR=1$ если для каждого пользователя мы рекомендовали хотя бы один релевантный объект. Так как обычно пользователи просматривают только первые $N$ рекомендаций, мы будем считать метрику $HR@N$, где $N=10$ (т.е. множество $Rec_u$ будет содержать только 10 объектов). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Условные обозначения\n",
    "* `uid` - идентификатор пользователя\n",
    "* `iid` - идентификатор объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games RSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# импорты, которые точно понадобятся\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import random\n",
    "from scipy.sparse import save_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Данные взяты отсюда - http://jmcauley.ucsd.edu/data/amazon/\n",
    "# http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Video_Games_5.json.gz\n",
    "JSON_DATA_PATH = \"lab_data/Video_Games_5.json\"\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def iter_json_data(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "            \n",
    "def get_data_frame():\n",
    "    uid_to_id = {}\n",
    "    iid_to_id = {}\n",
    "    \n",
    "    cols = [\"uid\", \"iid\", \"review\", \"rating\", \"dt\"]\n",
    "    rows = []\n",
    "    for d in iter_json_data(JSON_DATA_PATH):\n",
    "        uid = uid_to_id.setdefault(d[\"reviewerID\"], len(uid_to_id))\n",
    "        iid = iid_to_id.setdefault(d[\"asin\"], len(iid_to_id))\n",
    "        review = d[\"reviewText\"]\n",
    "        rating = float(d[\"overall\"])\n",
    "        dt = int(d[\"unixReviewTime\"])\n",
    "        rows.append((uid, iid, review, rating, dt))\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1403913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1315958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid                                             review  rating  \\\n",
       "0    0    0  Installing the game was a struggle (because of...     1.0   \n",
       "1    1    0  If you like rally cars get this game you will ...     4.0   \n",
       "2    2    0  1st shipment received a book instead of the ga...     1.0   \n",
       "3    3    0  I got this version instead of the PS3 version,...     3.0   \n",
       "4    4    0  I had Dirt 2 on Xbox 360 and it was an okay ga...     4.0   \n",
       "\n",
       "           dt  \n",
       "0  1341792000  \n",
       "1  1372550400  \n",
       "2  1403913600  \n",
       "3  1315958400  \n",
       "4  1308009600  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min-max количество объектов на пользователя: 5 773\n",
      "min-max количество пользователей на объект: 5 802\n"
     ]
    }
   ],
   "source": [
    "print(\"min-max количество объектов на пользователя:\", \n",
    "      df.groupby(\"uid\").iid.nunique().min(), df.groupby(\"uid\").iid.nunique().max())\n",
    "print(\"min-max количество пользователей на объект:\", \n",
    "      df.groupby(\"iid\").uid.nunique().min(), df.groupby(\"iid\").uid.nunique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем, есть ли случаи, когда один и тот же пользователь оставляет отзывы на один и тот же объект\n",
    "df.groupby([\"uid\", \"iid\"]).review.count().unique()  # ура, таких случаев нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов: 10672\n",
      "Количество пользователей: 24303\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество объектов:\", df.iid.unique().size)\n",
    "print(\"Количество пользователей:\", df.uid.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df_by_dt(df, p=0.8):\n",
    "    \"\"\"Функция разбивает df на тестовую и тренировочную выборки по времени \n",
    "    публикации отзывов (значение времени в поле dt)\n",
    "    \n",
    "    :param p: персентиль значений dt, которые образуют тренировочную выборку. Например p=0.8 означает, что в \n",
    "    тренировочной части будут отзывы, соответствующие первым 80% временного интервала \n",
    "    :return: два pd.DataFrame объекта\n",
    "    \"\"\"\n",
    "    border_dt = df.dt.quantile(p)\n",
    "    print(\"Min=%s, border=%s, max=%s\" % (df.dt.min(), border_dt, df.dt.max()))\n",
    "    training_df, test_df  = df[df.dt <= border_dt], df[df.dt > border_dt]\n",
    "    print(\"Размер до очистки:\", training_df.shape, test_df.shape)\n",
    "    # удаляем из тестовых данных строки, соответствующие пользователям или объектам, \n",
    "    # которых нет в тренировочных данных \n",
    "    # (пользователи - избегаем проблем для персональных систем, объекты - для всех)\n",
    "    test_df = test_df[test_df.uid.isin(training_df.uid) & test_df.iid.isin(training_df.iid)]\n",
    "    print(\"Размер после очистки:\", training_df.shape, test_df.shape)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min=939859200, border=1377129600.0, max=1405987200\n",
      "Размер до очистки: (185427, 5) (46353, 5)\n",
      "Размер после очистки: (185427, 5) (19174, 5)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = split_df_by_dt(df, p=0.8)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df(df, min_review_per_uid, min_review_per_iid):\n",
    "    \"\"\"Функция удаляет из df строки, соответствующие пользователям и объектам, \n",
    "    у которых меньше min_review_per_uid и min_review_per_iid отзывов соответственно\n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "    while True:\n",
    "        review_per_uid = _df.groupby(\"uid\").review.count()\n",
    "        bad_uids = review_per_uid[review_per_uid < min_review_per_uid].index\n",
    "    \n",
    "        review_per_iid = _df.groupby(\"iid\").review.count()\n",
    "        bad_iids = review_per_iid[review_per_iid < min_review_per_iid].index\n",
    "        \n",
    "        if bad_uids.shape[0] > 0 or bad_iids.shape[0] > 0:\n",
    "            _df = _df[(~_df.uid.isin(bad_uids)) & (~_df.iid.isin(bad_iids))]\n",
    "        else:\n",
    "            break\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для упрощения тестирования предлагается использовать словарь следующего типа:\n",
    "\n",
    "```python\n",
    "recs = {\n",
    "    uid_1: {\n",
    "        iid_1: score_11,\n",
    "        iid_2: score_12,\n",
    "        ...\n",
    "    },\n",
    "    uid_2: {\n",
    "        iid_1: score_21,\n",
    "        iid_2: score_22,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "где `uid_i` - идентификатор тестового пользователя, `iid_j` - идентификатор рекомендованного объекта, а `score_ij` - предсказанный рейтинг/вес объекта `j` для пользователя `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_ratio(recs_dict, test_dict):\n",
    "    \"\"\"Функция считает метрику hit-ration для двух словарей\n",
    "    :recs_dict: словарь рекомендаций типа {uid: {iid: score, ...}, ...}\n",
    "    :test_dict: тестовый словарь типа {uid: {iid: score, ...}, ...}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for uid in test_dict:\n",
    "        if set(test_dict[uid].keys()).intersection(recs_dict.get(uid, {})):\n",
    "            hits += 1\n",
    "    return hits / len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_dict(test_df):\n",
    "    \"\"\"Функция, конвертирующая тестовый df в словарь\n",
    "    \"\"\"\n",
    "    test_dict = {}\n",
    "    for t in test_df.itertuples():\n",
    "        test_dict.setdefault(t.uid, {})\n",
    "        test_dict[t.uid][t.iid] = t.rating\n",
    "    return test_dict\n",
    "\n",
    "test_dict = get_test_dict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые классы для рекомендательной системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BasicRecommender(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        \"\"\"Строит рекомендации для пользователя uid\n",
    "        :return: словарь типа {iid: score, ...}\n",
    "        \"\"\"\n",
    "        return {}\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        \"\"\"Строит рекомендации для нескольких пользователей uids\n",
    "        :return: словарь типа {uid: {iid: score, ...}, ...}\n",
    "        \"\"\"\n",
    "        return {uid: self.get_recs(uid, top) for uid in uids}\n",
    "    \n",
    "class NonPersRecommender(BasicRecommender):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.recs = self._prepare_recs(df)\n",
    "        \n",
    "    def _prepare_recs(self, df):\n",
    "        return pd.Series([])\n",
    "    \n",
    "    def get_recs(self, uid, top):\n",
    "        from collections import OrderedDict\n",
    "        return OrderedDict(self.recs[:top])\n",
    "    \n",
    "    def get_batch_recs(self, uids, top):\n",
    "        non_pers_recs = self.get_recs(None, top)\n",
    "        return {uid: non_pers_recs for uid in uids}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Content-based RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простая content-based рекомендательная система описывает пользователей и объекты как вектора в некотором N-мерном пространстве фич. Вектор объекта показывает, насколько объект принадлежит к той или иной фиче. Вектор пользователя показывает, насколько пользователь предпочитает ту или иную фичу. Рекомендации строятся путем поиска объектов, чьи вектора похожи на вектор предпочтений пользователя. Предполагается, что чем более похожи вектора пользователя и объекта, тем интереснее этот объект пользователю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HR@10` для content-based, модели созданной автором блокнота: 0.065"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-based CF основан на идее, что пользователь предпочтет объекты, похожие на те, что он приобретал ранее. Данные в CF модели представлены матрицей `user x item`, где ячейка матрицы соответствует рейтингу, который пользователь поставил объекту. Вместо рейтингов в матрице могут быть вероятности (т.е. вероятность, что пользователь воспользуется объектом). Для работы модели необходимо построить матрицу `item x item` схожести объектов. Обычно для построения матрицы схожести используется исходная матрица `user x item`. Чтобы уменьшить шумы в матрице схожести, для каждого объекта хранят только $K$ наиболее похожих объектов.\n",
    "\n",
    "В простейшем случае рекомендации строятся путем нахождения объектов с наибольшим значением предсказанного рейтинга:\n",
    "$$\\hat{r}_{ui} = \\frac{\\sum_{j \\in I_u} r_{uj} * sim(j, i)}{\\sum_{j \\in I_u} r_{uj}}$$\n",
    "\n",
    "* $I_u$ - множество объектов, оцененных пользователем\n",
    "* $sim(j, i)$ - схожесть между объектами $j$ и $i$\n",
    "\n",
    "Часто из финальных рекомендаций для пользователя $u$ исключаются объекты $I_u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вспомогательные функции, которые могут пригодиться при построении Item-based CF\n",
    "def nullify_main_diagonal(m):\n",
    "    positions = range(m.shape[0])\n",
    "    eye = csr_matrix((np.ones(len(positions)), (positions, positions)), m.shape)\n",
    "    return m - m.multiply(eye)\n",
    "\n",
    "\n",
    "def get_topk(matrix, top, axis=1):\n",
    "    \"\"\"Converts source matrix to Top-K matrix\n",
    "    where each row or column contains only top K values\n",
    "\n",
    "    :param matrix: source matrix\n",
    "    :param top: number of top items to be stored\n",
    "    :param axis: 0 - top by column, 1 - top by row\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    if axis == 0:\n",
    "        matrix = matrix.T.tocsr()\n",
    "\n",
    "    for row_id, row in enumerate(matrix):\n",
    "        if top is not None and row.nnz > top:\n",
    "            top_args = np.argsort(row.data)[-top:]\n",
    "\n",
    "            rows += [row_id] * top\n",
    "            cols += row.indices[top_args].tolist()\n",
    "            data += row.data[top_args].tolist()\n",
    "        elif row.nnz > 0:\n",
    "            rows += [row_id] * row.nnz\n",
    "            cols += row.indices.tolist()\n",
    "            data += row.data.tolist()\n",
    "\n",
    "    topk_m = csr_matrix((data, (rows, cols)), (matrix.shape[0], matrix.shape[1]))\n",
    "\n",
    "    if axis == 0:\n",
    "        topk_m = topk_m.T.tocsr()\n",
    "\n",
    "    return topk_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_ids = training_df.iid.unique() # уникальные идентификаторы объектов в тренировочной выборке\n",
    "ids_reviews = {}\n",
    "\n",
    "# для каждого id из item_ids формируется \"суммарное\" описание из отзывово нескольких пользователей\n",
    "for id in item_ids:\n",
    "    text = training_df[training_df.iid == id].review.str.cat(sep=' ')\n",
    "    ids_reviews[id] = text\n",
    "\n",
    "texts = [review for _, review in ids_reviews.items() ] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.corpus\n",
    "from nltk import word_tokenize, wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем словари для препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown = set(nltk.corpus.brown.words())\n",
    "pr_1 = set(nltk.corpus.product_reviews_1.words())\n",
    "pr_2 = set(nltk.corpus.product_reviews_2.words())\n",
    "web = set(nltk.corpus.webtext.words())\n",
    "nps = set(nltk.corpus.nps_chat.words())\n",
    "reuters = set(nltk.corpus.reuters.words())\n",
    "names = set(nltk.corpus.names.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = set()\n",
    "for dict_ in [brown, pr_1, pr_2, web, nps, reuters, names]:\n",
    "    dictionary = dictionary.union(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor(object):\n",
    "    def __init__(self, dictionary):\n",
    "        self.dictionary = dictionary\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        dict_ = self.dictionary\n",
    "        proc_text = \" \".join(w for w in wordpunct_tokenize(text) if w.lower() in dict_)\n",
    "        return proc_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = TextPreprocessor(dictionary).preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<bound method TextPreprocessor.preprocess of <__main__.TextPreprocessor object at 0x34D15990>>,\n",
       "        smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tfidf = TfidfVectorizer(stop_words='english', preprocessor=pp)\n",
    "my_tfidf.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61309"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DICT_LEN = len(my_tfidf.vocabulary_)\n",
    "DICT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_items = []\n",
    "id_to_ind = {} #словарь соответсвия id объекта и номера строки в матрице объектов\n",
    "for id in item_ids:\n",
    "    list_of_items.append(ids_reviews[id])\n",
    "    id_to_ind[id] = id_to_ind.setdefault(id, len(id_to_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_matrix = my_tfidf.transform(list_of_items) #матрица объектов \n",
    "del list_of_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10098x61309 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7542023 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012182270924150295"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_matrix.nnz/(items_matrix .shape[0]*items_matrix .shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим профили пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "from math import ceil\n",
    "\n",
    "uid_to_ind = {}\n",
    "ind_to_uid = {}\n",
    "\n",
    "#формируем разбиение списка пользователей для демпфирования матрицы пользователя\n",
    "user_rows = len(training_df.uid.unique())\n",
    "Nsplit = 20 #число разбиений\n",
    "block = ceil(user_rows/Nsplit)\n",
    "\n",
    "# создаем список диапазонов индексов\n",
    "block_list = []\n",
    "for i in range(Nsplit+1):\n",
    "    val = i*block\n",
    "    if val > user_rows:\n",
    "        val = user_rows\n",
    "    block_list.append(val)\n",
    "\n",
    "    \n",
    "for uid in training_df.uid.unique():\n",
    "    uid_to_ind[uid] = uid_to_ind.setdefault(uid, len(uid_to_ind))\n",
    "\n",
    "ind_to_uid = { v: k for k,v in uid_to_ind.items() }\n",
    "\n",
    "for i in range(Nsplit):\n",
    "    for k in range(block_list[i], block_list[i+1]):\n",
    "        uid = ind_to_uid[k]\n",
    "        user_df = training_df[training_df.uid == uid] #выбираем кусок df, соответствующий пользователю\n",
    "        user_items = user_df.iid                      #список объектов, оцененных пользователем\n",
    "        user_ratings = user_df.rating                 #рейтинги пользователя\n",
    "\n",
    "        user_vect = csr_matrix((1, DICT_LEN))         #инициализируем пустой вектор пользователя\n",
    "        users_list = []\n",
    "\n",
    "        for iid, rating in zip(user_items, user_ratings):\n",
    "            item_vect = items_matrix.getrow(id_to_ind[iid])\n",
    "            user_vect += item_vect.multiply(rating)\n",
    "            users_list.append(user_vect)\n",
    "        try:\n",
    "            users_matrix = vstack([users_matrix, user_vect])\n",
    "        except NameError:\n",
    "            users_matrix = user_vect\n",
    "        #users_matrix = vstack(users_list)\n",
    "    save_npz('user_'+str(i), users_matrix)\n",
    "    del users_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_npz('items_matrix', items_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-86b3a4e5b630>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNsplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0musers_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.npz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msimilarity_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msave_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'similarity_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\data_sci\\lib\\site-packages\\scipy\\sparse\\_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmatrix_format\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bsr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indices'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'indptr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmatrix_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'dia'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'offsets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloaded\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shape'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\data_sci\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 return format.read_array(bytes,\n\u001b[0;32m    232\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[0;32m    234\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\data_sci\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(Nsplit):\n",
    "    users_matrix = load_npz('user_'+str(i)+'.npz')\n",
    "    similarity_matrix = cosine_similarity(users_matrix, items_matrix, dense_output=False)\n",
    "    save_npz('similarity_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3284, 2339)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.shape #users x items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выбирает соответсвие id объекта - rating, уже приобретенные объекты (exclude keys) исключаются\n",
    "def select_item(source_matrix, keys_to_index, key_, exclude_keys):\n",
    "    if key_ in exclude_keys:\n",
    "        return 0\n",
    "    else:\n",
    "        return source_matrix[0, keys_to_index[key_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ContentBasedRecommender_dummy(NonPersRecommender):\n",
    "    \n",
    "    def __init__(self, uid_to_ind, iid_to_ind, train_df, sim_matrix):\n",
    "        super(NonPersRecommender, self).__init__()\n",
    "        self.uid_to_ind = uid_to_ind\n",
    "        self.iid_to_ind = iid_to_ind\n",
    "        self.train_df = train_df\n",
    "        self.sim_matrix = sim_matrix\n",
    "        #self.recs = self._prepare_recs(uid_to_ind, iid_to_ind, train_df, sim_matrix)\n",
    "        \n",
    "    def get_recs(self, uids_to_recommend, top_k=10):\n",
    "        self.recs = self._prepare_recs(uids_to_recommend, self.uid_to_ind, self.iid_to_ind, self.train_df, self.sim_matrix, top_k)\n",
    "        return self.recs\n",
    "        \n",
    "    def _prepare_recs(self, uids_to_recommend, uid_to_ind, iid_to_ind, train_df, sim_matrix, top_k):\n",
    "        out = {}\n",
    "        for uid in uids_to_recommend:\n",
    "            already_bought_items = train_df[train_df.uid == uid].iid.values\n",
    "            sim_row = sim_matrix.getrow(uid_to_ind[uid]).todense()\n",
    "            item_with_score = { iid: select_item(sim_row, iid_to_ind, iid, already_bought_items) for iid in iid_to_ind.keys() }\n",
    "            dummy = pd.Series(item_with_score).sort_values(ascending=False)[:top_k].to_dict()\n",
    "            out[uid] = dummy\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommender = ContentBasedRecommender_dummy(uid_to_ind, id_to_ind, training_df, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uids_to_recommend = test_df.uid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3389,)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uids_to_recommend.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recommends = recommender.get_recs(uids_to_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recommends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12056737588652482"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_ratio(recommends, test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HR@10` для item-based CF модели, созданной автором блокнота: 0.085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подcказки\n",
    "* Определитесь с тем, что вы пытаетесь предсказать (рейтинги, вероятности, ...)\n",
    "* Оптимальный способ вычисления матрицы схожести выглядит так:\n",
    " * Привести строки в матрице `user x item` к единичной длине (выделяет основные предпочтения пользователя)\n",
    " * Построить матрицу схожести `item x item`\n",
    " * Для каждого объекта оставить только $K$ наиболее похожих объектов\n",
    " * Для каждого объекта привести к единичной длине вектор схожести этого объекта (выделяет наиболее схожие объекты)\n",
    "* Удалили ли вы из рекомендаций объекты, которые пользователь уже оценивал?\n",
    "* Статья \"Item-Based Top-N Recommendation Algorithms\", Mukund Deshpande и George Karypis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гибридная рекомендательная система - это объединение нескольких рекомендательных систем (мы не будем перечислять тут возможные способы гибридизации). Цель гибридизации - воспользоваться сильными сторонами нескольких моделей, чтобы улучшить качество рекомендаций.\n",
    "\n",
    "В данном задании студент должен создать гибридную систему, состояющую **как минимум** из двух подсистем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HR@10` для гибридной модели, созданной автором блокнота: 0.096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подcказки\n",
    "* Определите сильные и слабые стороны различных моделей\n",
    "* Какие из них коррелируют? А какие могут дополнять друг друга?\n",
    "* Только конечный результат работы системы должен содержать $N$ рекомендаций (промежуточные могут содержать больше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P.S.\n",
    "В коде возможны пасхальные яйца ]:->, если у вас возникли вопросы, не стесняйтесь их задавать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
